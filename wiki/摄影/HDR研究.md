

---

以下是自己的聊天记录：

今天深入学习了一下相机sensor，终于搞清楚了之前一直炒的HDR视频概念

大宽容度，还是得靠摄像设备sensor本身的性能，后面那些视频格式、显示设备，都是忽悠人的，为了HDR而HDR

 所谓HDR，从终端用户眼里，就是和人眼视觉相似的效果嘛

要得到这样的效果，我们需要啥

录像、存储、回放，哪一步是最重要的？ 

首先，对于录像设备，怎么样才能拿到做HDR的数据，不靠后期用多次成像的数据合成

 那就是提高sensor每个像素的分辨率（就是AD采样位数嘛）

然后通过RAW数据，做曲线调整，着色、渲染出逼近人眼的效果

 至于存储，能提高的是色彩深度，那现行的格式，能满足我们人眼的需要了吗，人眼能识别全这些颜色了吗

从直觉上，现在的YUV色域，已经是大大超过人眼的视觉范围了。。储存上的提升应该是微小的

再到回放，显示器上像素的“宽容度”，也就是——一个像素点能多黑、能多亮
其实到了OLED时代——能多黑，已经是能完全黑了。。能多亮，得看你眼睛能受得了多亮。。这些都不太成问题

我觉得可以提升的点在于亮度区间里，分辨率的准确度，

特别是暗色区间

但是这。。能提升多少？ 对于人眼而言，现在一张我们人工合成的HDR照片，放到屏幕上，我们能有很明显的提升体验吧？
那我们再对屏幕加强，能提升多少。。？
直觉上也是很微小的提升

 所以结论是，HDR的关键在于录像设备。。。

但是厂商们为了盈利，都在炒新格式、新标准，这个应该是标准和商业竞争的问题，与技术无关

不一定对，欢迎交流讨论，这是短时间初步学习得到的结论